<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Behavior Testing for Time Series Forecasting with Prophet | Hello there!</title>
<meta name=keywords content="flair,prophet,timeseries-forecasting,ml-evaluation,behavior-testing"><meta name=description content="Behavioral testing for time series forecasting models can be used to assess their adaptability to sudden changes in historical data. In this blog post, I am using the Prophet framework to evaluate the model&rsquo;s response to permanent shocks within a time series."><meta name=author content="Fran Peric"><link rel=canonical href=https://franperic.github.io/posts/flair/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://franperic.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://franperic.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://franperic.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://franperic.github.io/apple-touch-icon.png><link rel=mask-icon href=https://franperic.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-PHGB9VX84Y"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PHGB9VX84Y",{anonymize_ip:!1})}</script><meta property="og:title" content="Behavior Testing for Time Series Forecasting with Prophet"><meta property="og:description" content="Behavioral testing for time series forecasting models can be used to assess their adaptability to sudden changes in historical data. In this blog post, I am using the Prophet framework to evaluate the model&rsquo;s response to permanent shocks within a time series."><meta property="og:type" content="article"><meta property="og:url" content="https://franperic.github.io/posts/flair/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-29T15:50:26+01:00"><meta property="article:modified_time" content="2023-11-29T15:50:26+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Behavior Testing for Time Series Forecasting with Prophet"><meta name=twitter:description content="Behavioral testing for time series forecasting models can be used to assess their adaptability to sudden changes in historical data. In this blog post, I am using the Prophet framework to evaluate the model&rsquo;s response to permanent shocks within a time series."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://franperic.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Behavior Testing for Time Series Forecasting with Prophet","item":"https://franperic.github.io/posts/flair/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Behavior Testing for Time Series Forecasting with Prophet","name":"Behavior Testing for Time Series Forecasting with Prophet","description":"Behavioral testing for time series forecasting models can be used to assess their adaptability to sudden changes in historical data. In this blog post, I am using the Prophet framework to evaluate the model\u0026rsquo;s response to permanent shocks within a time series.","keywords":["flair","prophet","timeseries-forecasting","ml-evaluation","behavior-testing"],"articleBody":"tl;dr Behavioral testing for time series forecasting models can be used to assess their adaptability to sudden changes in historical data. In this blog post, I am using the Prophet framework to evaluate the model’s response to permanent shocks within a time series.\nWhat is behavior testing? Behavior testing is a methodology for evaluating the adaptability of a model to sudden changes in historical data. It is a form of stress testing that simulates shocks within the time series and observes the model’s response. This approach can be used to assess the model’s ability to adapt to new patterns and eventually stabilize.\nWhy is behavior testing important? Time series forecasting models are often trained on historical data and used to predict future trends. However, these models may not be able to adapt to sudden changes in the data, such as economic downturns or shifts in consumer behavior. Behavior testing can be used to evaluate the model’s ability to handle such changes and provide insights into its adaptability.\nLets dive into it Example data I will use a dataset from the M4 competition to demonstrate the behavior testing approach. The dataset contains 100,000 time series from different domains and various frequencies. For the demonstration purposes, I randomly picked a monthly time series from the dataset - the time series with the ID M54.\nGenerating a permanent shock The first step is to introduce a simulated permanent shock within the time series. This shock can mimic sudden changes, such as economic downturns, shifts in consumer behavior, or anomalies affecting the data. In this example, I will simulate a positive permanent shock by multiplying the time series values by a factor of 1.2. I use the forecasting horizon of 12 months to evaluate the model’s prediction performance.\nAt t = 12 the shock is introduced. In the illustration below, the simulated values are shown in orange. Green is the last observation in the training data.\nThe prediction performance is evaluated for 12 time steps after the shock was introduced (t = 12, t = 13, …, t = 23). In this example I will use the mean absolute percentage error (MAPE) as the evaluation metric.\nIllustration of the behavior testing methodology To get a robust approximation of the adaptibility of the model, I will repeat the experiment 10 times. Each time I will randomly pick a new date to introduce the shock. The following plot shows the 10 randomly selected intervention dates, where the shock is introduced.\nThe plots are created using the plotly library. You can zoom in and interact with the graphs.\nThe global results In the table below the global results are shown. Later in this blog post, I will deep dive into a single simulation run in more detail. The results are aggregated across all simulations. The median adaption time in this example is 1 month, while the mean adaption time is 4.5 months with a standard deviation of 5.32 months.\nWhat is the adaption time?\nThe adaption time is the number of months required for the model to regain a level of accuracy comparable to its pre-shock performance.\nStatistic Value Runs 10.000 Median 1.000 Mean 4.500 Std 5.315 Min 0.000 Max 12.000 Global results of the behavior testing The distribution of the adaption time is shown in the histogram below. The majority of the simulations (6 out of 10) required less than 2 months to recover from the shock. However, in 3 cases the model did not recover at all in the evaluation period of 12 months.\nThe following table shows the aggregated results for each simulation run. One simulation run consists of 12 evaluation steps before the shock, in order to establish a benchmark prediciton performance, and 12 evaluation steps after the shock.\nsim_mape is the mean absolute percentage error (MAPE) of the Prophet model on the simulated data.\nsim_mape_std is the standard deviation of the MAPE across the 12 simulated time steps.\nbenchmark_mape is the MAPE of the Prophet model on 12 months before the simulation shock.\nadaption_time is the number of months required for the model to regain a level of accuracy comparable to its pre-shock performance.\nrun sim_mape sim_mape_std benchmark_mape adaption_time 0 0.165 0.091 1.067 0 1 0.219 0.053 0.194 7 2 0.144 0.010 0.049 12 3 0.300 0.198 1.319 0 4 0.189 0.008 0.039 12 5 0.238 0.129 0.333 2 6 0.213 0.030 0.189 0 7 0.354 0.134 0.582 0 8 0.548 0.208 0.291 0 9 0.110 0.021 0.060 12 Simulation summary What does simulation run 1 look like? In this section, I will deep dive into a single simulation run, run 1. The plot below shows each evaluation step of the simulation run. The blue line is the actual time series, the green line is the simulated time series, and the red line is the Prophet model’s prediction with a prediction horizon of 12 months.\nThe shock is introduced at evaluation step 12. The prior 12 evaluation steps are used to establish a benchmark prediction performance. The MAPEs before and after the shock are shown in the next plot.\nThis plot shows the MAPEs before and after the shock, blue and red line correspondingly. The prediction performance before the shock is 0.194 (grey horizontal line). It is used to assess how long it takes for the model to recover from the shock.\nAs expected the MAPE jumps significantly after the introduction of the shock. The model needs 7 months to recover from the shock and regain a level of accuracy comparable to its pre-shock performance.\nConclusion Behavior testing can be used to evaluate the adaptability of a time series forecasting model to sudden changes in historical data. In this blog post, I used Prophet, one of the most widely used time series forecasting frameworks. I am not advocating for Prophet, but I am using it as an example to demonstrate the behavior testing approach.\nThe results show that the model needs on average 4.5 months to recover from the shock and regain a level of accuracy comparable to its pre-shock performance. This finding is true to this specific time series in combination with the Prophet model. The results will vary for other time series and models.\nHopefully, this blog post provides you with a new perspective on time series forecasting models and their evaluation. If you are interested in behavioral testing for time series forecasting models, I have created a python package called flair. The package is still in its early stages, but I am working on adding more features and improving the documentation.\nIf you have any questions or feedback, please reach out to me on Twitter.\n","wordCount":"1106","inLanguage":"en","datePublished":"2023-11-29T15:50:26+01:00","dateModified":"2023-11-29T15:50:26+01:00","author":{"@type":"Person","name":"Fran Peric"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://franperic.github.io/posts/flair/"},"publisher":{"@type":"Organization","name":"Hello there!","logo":{"@type":"ImageObject","url":"https://franperic.github.io/favicon.ico"}}}</script></head><body id=top><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-PHGB9VX84Y"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PHGB9VX84Y",{anonymize_ip:!1})}</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-PHGB9VX84Y","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://franperic.github.io accesskey=h title="Hello there! (Alt + H)">Hello there!</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://franperic.github.io/posts title=Posts><span>Posts</span></a></li><li><a href=https://franperic.github.io/talks title=Talks><span>Talks</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://franperic.github.io>Home</a>&nbsp;»&nbsp;<a href=https://franperic.github.io/posts/>Posts</a></div><h1 class=post-title>Behavior Testing for Time Series Forecasting with Prophet</h1><div class=post-meta>&lt;span title='2023-11-29 15:50:26 +0100 +0100'>November 29, 2023&lt;/span>&amp;nbsp;·&amp;nbsp;Fran Peric</div></header><div class=post-content><h1 id=tldr>tl;dr<a hidden class=anchor aria-hidden=true href=#tldr>#</a></h1><blockquote><p>Behavioral testing for time series forecasting models can be used to assess their adaptability to sudden changes in historical data. In this blog post, I am using the <a href=https://facebook.github.io/prophet/><em>Prophet</em></a> framework to evaluate the model&rsquo;s response to permanent shocks within a time series.</p></blockquote><hr><h2 id=what-is-behavior-testing>What is behavior testing?<a hidden class=anchor aria-hidden=true href=#what-is-behavior-testing>#</a></h2><p>Behavior testing is a methodology for evaluating the adaptability of a model to sudden changes in historical data. It is a form of stress testing that simulates shocks within the time series and observes the model&rsquo;s response. This approach can be used to assess the model&rsquo;s ability to adapt to new patterns and eventually stabilize.</p><h2 id=why-is-behavior-testing-important>Why is behavior testing important?<a hidden class=anchor aria-hidden=true href=#why-is-behavior-testing-important>#</a></h2><p>Time series forecasting models are often trained on historical data and used to predict future trends. However, these models may not be able to adapt to sudden changes in the data, such as economic downturns or shifts in consumer behavior. Behavior testing can be used to evaluate the model&rsquo;s ability to handle such changes and provide insights into its adaptability.</p><h2 id=lets-dive-into-it>Lets dive into it<a hidden class=anchor aria-hidden=true href=#lets-dive-into-it>#</a></h2><h3 id=example-data>Example data<a hidden class=anchor aria-hidden=true href=#example-data>#</a></h3><p>I will use a dataset from the <a href=https://github.com/Mcompetitions/M4-methods/tree/master/Dataset>M4 competition</a> to demonstrate the behavior testing approach. The dataset contains 100,000 time series from different domains and various frequencies. For the demonstration purposes, I randomly picked a monthly time series from the dataset - the time series with the ID <em>M54</em>.</p><iframe src=/flair/ts.html width=100% style=border:none;overflow:hidden;width:100%;height:500px></iframe><h3 id=generating-a-permanent-shock>Generating a permanent shock<a hidden class=anchor aria-hidden=true href=#generating-a-permanent-shock>#</a></h3><p>The first step is to introduce a simulated permanent shock within the time series. This shock can mimic sudden changes, such as economic downturns, shifts in consumer behavior, or anomalies affecting the data. In this example, I will simulate a positive permanent shock by multiplying the time series values by a factor of <strong>1.2</strong>. I use the forecasting horizon of 12 months to evaluate the model&rsquo;s prediction performance.</p><p>At <strong>t = 12</strong> the shock is introduced. In the illustration below, the simulated values are shown in orange. Green is the last observation in the training data.</p><p>The prediction performance is evaluated for 12 time steps after the shock was introduced (t = 12, t = 13, &mldr;, t = 23). In this example I will use the mean absolute percentage error (MAPE) as the evaluation metric.</p><figure><img src=/flair/flair-illustration.jpg></figure><div align=center><i>Illustration of the behavior testing methodology</i></div><br><p>To get a robust approximation of the adaptibility of the model, I will repeat the experiment 10 times. Each time I will randomly pick a new date to introduce the shock. The following plot shows the 10 randomly selected intervention dates, where the shock is introduced.</p><p>The plots are created using the <a href=https://plotly.com/python/>plotly</a> library. You can zoom in and interact with the graphs.</p><iframe src=/flair/interventions.html width=100% style=border:none;overflow:hidden;width:100%;height:3000px></iframe><h3 id=the-global-results>The global results<a hidden class=anchor aria-hidden=true href=#the-global-results>#</a></h3><p>In the table below the global results are shown. Later in this blog post, I will deep dive into a single simulation run in more detail. The results are aggregated across all simulations. The median adaption time in this example is 1 month, while the mean adaption time is 4.5 months with a standard deviation of 5.32 months.</p><p>What is the adaption time?</p><p>The adaption time is the number of months required for the model to regain a level of accuracy comparable to its pre-shock performance.</p><table style=margin-left:auto;margin-right:auto;width:25%><thead><tr style=text-align:right><th>Statistic</th><th>Value</th></tr></thead><tbody><tr><td>Runs</td><td>10.000</td></tr><tr><td>Median</td><td>1.000</td></tr><tr><td>Mean</td><td>4.500</td></tr><tr><td>Std</td><td>5.315</td></tr><tr><td>Min</td><td>0.000</td></tr><tr><td>Max</td><td>12.000</td></tr></tbody></table><div align=center><i>Global results of the behavior testing</i></div><br><p>The distribution of the adaption time is shown in the histogram below. The majority of the simulations (6 out of 10) required less than 2 months to recover from the shock. However, in 3 cases the model did not recover at all in the evaluation period of 12 months.</p><iframe src=/flair/adapt_hist.html width=100% style=border:none;overflow:hidden;width:100%;height:450px></iframe><p>The following table shows the aggregated results for each simulation run. One simulation run consists of 12 evaluation steps before the shock, in order to establish a benchmark prediciton performance, and 12 evaluation steps after the shock.</p><p><em>sim_mape</em> is the mean absolute percentage error (MAPE) of the Prophet model on the simulated data.</p><p><em>sim_mape_std</em> is the standard deviation of the MAPE across the 12 simulated time steps.</p><p><em>benchmark_mape</em> is the MAPE of the Prophet model on 12 months before the simulation shock.</p><p><em>adaption_time</em> is the number of months required for the model to regain a level of accuracy comparable to its pre-shock performance.</p><table style="margin:0 auto;width:80%"><thead><tr style=text-align:right><th>run</th><th>sim_mape</th><th>sim_mape_std</th><th>benchmark_mape</th><th>adaption_time</th></tr></thead><tbody><tr><td>0</td><td>0.165</td><td>0.091</td><td>1.067</td><td>0</td></tr><tr><td>1</td><td>0.219</td><td>0.053</td><td>0.194</td><td>7</td></tr><tr><td>2</td><td>0.144</td><td>0.010</td><td>0.049</td><td>12</td></tr><tr><td>3</td><td>0.300</td><td>0.198</td><td>1.319</td><td>0</td></tr><tr><td>4</td><td>0.189</td><td>0.008</td><td>0.039</td><td>12</td></tr><tr><td>5</td><td>0.238</td><td>0.129</td><td>0.333</td><td>2</td></tr><tr><td>6</td><td>0.213</td><td>0.030</td><td>0.189</td><td>0</td></tr><tr><td>7</td><td>0.354</td><td>0.134</td><td>0.582</td><td>0</td></tr><tr><td>8</td><td>0.548</td><td>0.208</td><td>0.291</td><td>0</td></tr><tr><td>9</td><td>0.110</td><td>0.021</td><td>0.060</td><td>12</td></tr></tbody></table><br><div align=center><i>Simulation summary</i></div><br><h3 id=what-does-simulation-run-1-look-like>What does simulation run 1 look like?<a hidden class=anchor aria-hidden=true href=#what-does-simulation-run-1-look-like>#</a></h3><p>In this section, I will deep dive into a single simulation run, run 1. The plot below shows each evaluation step of the simulation run. The blue line is the actual time series, the green line is the simulated time series, and the red line is the Prophet model&rsquo;s prediction with a prediction horizon of 12 months.</p><p>The shock is introduced at evaluation step 12. The prior 12 evaluation steps are used to establish a benchmark prediction performance. The MAPEs before and after the shock are shown in the next plot.</p><iframe src=/flair/detail.html width=100% style=border:none;overflow:hidden;width:100%;height:5050px></iframe><p>This plot shows the MAPEs before and after the shock, blue and red line correspondingly. The prediction performance before the shock is 0.194 (grey horizontal line). It is used to assess how long it takes for the model to recover from the shock.</p><p>As expected the MAPE jumps significantly after the introduction of the shock. The model needs 7 months to recover from the shock and regain a level of accuracy comparable to its pre-shock performance.</p><iframe src=/flair/mapes.html width=100% style=border:none;overflow:hidden;width:100%;height:450px></iframe><h3 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h3><p>Behavior testing can be used to evaluate the adaptability of a time series forecasting model to sudden changes in historical data. In this blog post, I used Prophet, one of the most widely used time series forecasting frameworks. I am not advocating for Prophet, but I am using it as an example to demonstrate the behavior testing approach.</p><p>The results show that the model needs on average 4.5 months to recover from the shock and regain a level of accuracy comparable to its pre-shock performance. This finding is true to this specific time series in combination with the Prophet model. The results will vary for other time series and models.</p><p>Hopefully, this blog post provides you with a new perspective on time series forecasting models and their evaluation. If you are interested in behavioral testing for time series forecasting models, I have created a python package called <a href=https://github.com/franperic/flair>flair</a>. The package is still in its early stages, but I am working on adding more features and improving the documentation.</p><p>If you have any questions or feedback, please reach out to me on <a href=https://twitter.com/fran_peric>Twitter</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://franperic.github.io/tags/flair/>flair</a></li><li><a href=https://franperic.github.io/tags/prophet/>prophet</a></li><li><a href=https://franperic.github.io/tags/timeseries-forecasting/>timeseries-forecasting</a></li><li><a href=https://franperic.github.io/tags/ml-evaluation/>ml-evaluation</a></li><li><a href=https://franperic.github.io/tags/behavior-testing/>behavior-testing</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://franperic.github.io>Hello there!</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".post-content img"));images.forEach(e=>{mediumZoom(e,{margin:0,scrollOffset:40,container:null,template:null})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>